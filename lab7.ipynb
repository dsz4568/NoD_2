{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1439d612-3fbe-47d7-8df1-9f67e5ba10e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# ## Analiza skupień dla Breast Cancer Wisconsin\n",
    "# \n",
    "# **Autor:** [Twoje Imię]  \n",
    "# **Data:** [Data]  \n",
    "# \n",
    "# ### Cel projektu\n",
    "# Porównanie trzech metod klasteryzacji (K-means, DBSCAN, Agglomerative Clustering) na danych Breast Cancer Wisconsin.\n",
    "\n",
    "# %%\n",
    "# Krok 1: Import niezbędnych bibliotek\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans, DBSCAN, AgglomerativeClustering\n",
    "from sklearn.metrics import silhouette_score, adjusted_rand_score\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# %%\n",
    "# Krok 2: Wczytanie i przygotowanie danych\n",
    "data = load_breast_cancer()\n",
    "X = data.data\n",
    "y = data.target\n",
    "feature_names = data.feature_names\n",
    "target_names = data.target_names\n",
    "\n",
    "print(f\"Liczba próbek: {X.shape[0]}\")\n",
    "print(f\"Liczba cech: {X.shape[1]}\")\n",
    "print(f\"Klasy: {np.unique(y)} -> {target_names}\")\n",
    "\n",
    "# Standaryzacja danych\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Redukcja wymiarów do wizualizacji\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "# Wizualizacja danych oryginalnych\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.scatterplot(x=X_pca[:, 0], y=X_pca[:, 1], hue=y, palette='viridis', s=50)\n",
    "plt.title('PCA: Rzeczywiste klasy')\n",
    "plt.xlabel('PCA 1')\n",
    "plt.ylabel('PCA 2')\n",
    "plt.legend(title='Klasa', labels=target_names)\n",
    "plt.show()\n",
    "\n",
    "# %%\n",
    "# Krok 3: K-means z różną liczbą skupień\n",
    "k_values = range(2, 11)\n",
    "silhouette_scores_kmeans = []\n",
    "ari_scores_kmeans = []\n",
    "\n",
    "for k in k_values:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42, n_init='auto')\n",
    "    cluster_labels = kmeans.fit_predict(X_scaled)\n",
    "    \n",
    "    # Obliczenie silhouette score\n",
    "    sil_score = silhouette_score(X_scaled, cluster_labels)\n",
    "    silhouette_scores_kmeans.append(sil_score)\n",
    "    \n",
    "    # Obliczenie Adjusted Rand Index (porównanie z prawdziwymi etykietami)\n",
    "    ari = adjusted_rand_score(y, cluster_labels)\n",
    "    ari_scores_kmeans.append(ari)\n",
    "\n",
    "# Wizualizacja wyników\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(k_values, silhouette_scores_kmeans, 'bo-')\n",
    "plt.xlabel('Liczba skupień (k)')\n",
    "plt.ylabel('Silhouette Score')\n",
    "plt.title('K-means: Współczynnik Silhouette')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(k_values, ari_scores_kmeans, 'ro-')\n",
    "plt.xlabel('Liczba skupień (k)')\n",
    "plt.ylabel('Adjusted Rand Index')\n",
    "plt.title('K-means: Dopasowanie do rzeczywistych klas')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# %%\n",
    "# Krok 4: DBSCAN z różnymi parametrami eps i min_samples\n",
    "eps_values = np.linspace(0.1, 1.0, 10)\n",
    "min_samples_values = [5, 10, 15, 20]\n",
    "results = []\n",
    "\n",
    "for eps in eps_values:\n",
    "    for min_samples in min_samples_values:\n",
    "        dbscan = DBSCAN(eps=eps, min_samples=min_samples)\n",
    "        cluster_labels = dbscan.fit_predict(X_scaled)\n",
    "        \n",
    "        # Pomijamy przypadki z tylko 1 klastrem\n",
    "        unique_labels = np.unique(cluster_labels)\n",
    "        n_clusters = len(unique_labels) - (1 if -1 in cluster_labels else 0)\n",
    "        \n",
    "        if n_clusters < 2:\n",
    "            continue\n",
    "            \n",
    "        sil_score = silhouette_score(X_scaled, cluster_labels)\n",
    "        ari = adjusted_rand_score(y, cluster_labels)\n",
    "        noise_ratio = np.sum(cluster_labels == -1) / len(cluster_labels)\n",
    "        \n",
    "        results.append({\n",
    "            'eps': eps,\n",
    "            'min_samples': min_samples,\n",
    "            'silhouette': sil_score,\n",
    "            'ari': ari,\n",
    "            'n_clusters': n_clusters,\n",
    "            'noise_ratio': noise_ratio\n",
    "        })\n",
    "\n",
    "# Konwersja wyników do DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Wizualizacja wyników\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "plt.subplot(2, 1, 1)\n",
    "sns.heatmap(results_df.pivot_table(index='eps', columns='min_samples', values='silhouette'), \n",
    "            annot=True, cmap='viridis', fmt=\".3f\")\n",
    "plt.title('DBSCAN: Silhouette Score')\n",
    "plt.xlabel('min_samples')\n",
    "plt.ylabel('eps')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "sns.heatmap(results_df.pivot_table(index='eps', columns='min_samples', values='ari'), \n",
    "            annot=True, cmap='plasma', fmt=\".3f\")\n",
    "plt.title('DBSCAN: Adjusted Rand Index')\n",
    "plt.xlabel('min_samples')\n",
    "plt.ylabel('eps')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# %%\n",
    "# Krok 5: Agglomerative Clustering\n",
    "# Hierarchiczna wizualizacja\n",
    "plt.figure(figsize=(12, 8))\n",
    "linked = linkage(X_scaled, 'ward')\n",
    "dendrogram(linked, truncate_mode='level', p=5)\n",
    "plt.title('Dendrogram')\n",
    "plt.xlabel('Indeks próbki')\n",
    "plt.ylabel('Odległość')\n",
    "plt.show()\n",
    "\n",
    "# %%\n",
    "# Krok 6: Porównanie wszystkich trzech metod\n",
    "# Wybór najlepszych parametrów\n",
    "best_k = k_values[np.argmax(silhouette_scores_kmeans)]\n",
    "print(f\"Optymalna liczba klastrów dla K-means: {best_k}\")\n",
    "\n",
    "best_dbscan_row = results_df.loc[results_df['silhouette'].idxmax()]\n",
    "print(f\"Optymalne parametry DBSCAN: eps={best_dbscan_row['eps']:.2f}, min_samples={best_dbscan_row['min_samples']}\")\n",
    "\n",
    "# Klasteryzacja z optymalnymi parametrami\n",
    "kmeans = KMeans(n_clusters=best_k, random_state=42, n_init='auto')\n",
    "kmeans_labels = kmeans.fit_predict(X_scaled)\n",
    "\n",
    "dbscan = DBSCAN(eps=best_dbscan_row['eps'], min_samples=int(best_dbscan_row['min_samples']))\n",
    "dbscan_labels = dbscan.fit_predict(X_scaled)\n",
    "\n",
    "agg = AgglomerativeClustering(n_clusters=best_k)\n",
    "agg_labels = agg.fit_predict(X_scaled)\n",
    "\n",
    "# Obliczenie metryk\n",
    "metrics = []\n",
    "for name, labels in zip(['K-means', 'DBSCAN', 'Agglomerative'],\n",
    "                       [kmeans_labels, dbscan_labels, agg_labels]):\n",
    "    unique_labels = np.unique(labels)\n",
    "    n_clusters = len(unique_labels) - (1 if -1 in labels else 0)\n",
    "    \n",
    "    if n_clusters > 1:  # silhouette_score wymaga >1 klastra\n",
    "        sil = silhouette_score(X_scaled, labels)\n",
    "    else:\n",
    "        sil = -1\n",
    "        \n",
    "    ari = adjusted_rand_score(y, labels)\n",
    "    noise_ratio = np.sum(labels == -1) / len(labels) if -1 in labels else 0\n",
    "    \n",
    "    metrics.append({\n",
    "        'Metoda': name,\n",
    "        'Liczba klastrów': n_clusters,\n",
    "        'Silhouette': sil,\n",
    "        'Adjusted Rand Index': ari,\n",
    "        'Procent szumu (%)': noise_ratio * 100\n",
    "    })\n",
    "\n",
    "metrics_df = pd.DataFrame(metrics)\n",
    "\n",
    "# Wizualizacja wyników\n",
    "plt.figure(figsize=(18, 5))\n",
    "\n",
    "for i, (name, labels) in enumerate(zip(['K-means', 'DBSCAN', 'Agglomerative'],\n",
    "                                     [kmeans_labels, dbscan_labels, agg_labels]), 1):\n",
    "    plt.subplot(1, 3, i)\n",
    "    scatter = sns.scatterplot(x=X_pca[:, 0], y=X_pca[:, 1], \n",
    "                    hue=labels, palette='viridis', \n",
    "                    style=y, s=70, alpha=0.8)\n",
    "    plt.title(f'{name}\\nLiczba klastrów: {metrics_df.iloc[i-1][\"Liczba klastrów\"]}')\n",
    "    plt.xlabel('PCA 1')\n",
    "    plt.ylabel('PCA 2')\n",
    "    \n",
    "    # Dodanie legendy tylko dla pierwszego wykresu\n",
    "    if i == 1:\n",
    "        handles, _ = scatter.get_legend_handles_labels()\n",
    "        plt.legend(handles, ['Klaster', 'Klasy (kształt)'], loc='best')\n",
    "    else:\n",
    "        plt.legend([], [], frameon=False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Wyświetlenie tabeli z metrykami\n",
    "display(metrics_df)\n",
    "\n",
    "# %%\n",
    "# Krok 7: Analiza wyników\n",
    "print(\"\\nPodsumowanie wyników:\")\n",
    "print(\"1. K-means:\")\n",
    "print(f\"   - Optymalna liczba klastrów: {best_k}\")\n",
    "print(f\"   - Silhouette: {metrics_df[metrics_df['Metoda']=='K-means']['Silhouette'].values[0]:.4f}\")\n",
    "print(f\"   - ARI: {metrics_df[metrics_df['Metoda']=='K-means']['Adjusted Rand Index'].values[0]:.4f}\")\n",
    "\n",
    "print(\"\\n2. DBSCAN:\")\n",
    "print(f\"   - Najlepsze parametry: eps={best_dbscan_row['eps']:.2f}, min_samples={best_dbscan_row['min_samples']}\")\n",
    "print(f\"   - Liczba klastrów: {metrics_df[metrics_df['Metoda']=='DBSCAN']['Liczba klastrów'].values[0]}\")\n",
    "print(f\"   - Silhouette: {metrics_df[metrics_df['Metoda']=='DBSCAN']['Silhouette'].values[0]:.4f}\")\n",
    "print(f\"   - ARI: {metrics_df[metrics_df['Metoda']=='DBSCAN']['Adjusted Rand Index'].values[0]:.4f}\")\n",
    "print(f\"   - Szum: {metrics_df[metrics_df['Metoda']=='DBSCAN']['Procent szumu (%)'].values[0]:.2f}%\")\n",
    "\n",
    "print(\"\\n3. Agglomerative Clustering:\")\n",
    "print(f\"   - Liczba klastrów: {best_k}\")\n",
    "print(f\"   - Silhouette: {metrics_df[metrics_df['Metoda']=='Agglomerative']['Silhouette'].values[0]:.4f}\")\n",
    "print(f\"   - ARI: {metrics_df[metrics_df['Metoda']=='Agglomerative']['Adjusted Rand Index'].values[0]:.4f}\")\n",
    "\n",
    "print(\"\\nWnioski:\")\n",
    "print(\"- Wszystkie metody osiągnęły dobre wyniki ARI (>0.5), co wskazuje na zgodność z rzeczywistymi klasami\")\n",
    "print(\"- K-means i Agglomerative Clustering dały podobne wyniki\")\n",
    "print(\"- DBSCAN zidentyfikował punkty szumowe (ok. 10% danych)\")\n",
    "print(\"- Metoda Agglomerative ma najwyższy współczynnik Silhouette\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
